{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## webBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://blog.langchain.dev/customers-replit/'}, page_content='\\nReplit is at the forefront of AI innovation with its platform that simplifies writing, running, and collaborating on code for over 30+ million developers. They recently released Replit Agent, which immediately went viral due to the incredible applications people could easily create with this tool.Behind the scenes, Replit Agent has a complex workflow built on LangGraph, which enables a highly custom agentic workflow with a high-degree of control and parallel execution. A major benefit of using LangGraph was the seamless integration with LangSmith, which gave Replit deep visibility into their agent interactions to debug tricky issues.\\xa0The level of complexity required for Replit Agent also pushed the boundaries of LangSmith. The LangChain and Replit teams worked closely together to add functionality to LangSmith that would satisfy their LLM observability needs. Specifically, there were three main areas that we innovated on:Improved performance and scale on large tracesAbility to search and filter within tracesThread view to enable human-in-the loop workflowsImproved performance and scale on large tracesMost other LLMOps solutions monitor individual API requests to LLM providers, offering a limited view of single LLM calls. In contrast, LangSmith from day one has focused on tracing the entire execution flow of an LLM application to provide a more holistic context.\\xa0Tracing is important for agents due to their complex nature. It captures multiple LLM calls as well as other steps (retrieval, running code, etc). This gives you granular visibility into what’s happening, including at the inputs and outputs of each step, in order to understand the agent’s decision-making.\\xa0Replit Agent was a ripe example for advanced tracing needs. Their agentic tool goes beyond simply reviewing and writing code, but also performs a wider range of functions – including planning, creating dev environments, installing dependencies, and deploying applications for users.\\xa0As a result, Replit’s traces were very large - involving hundreds of steps. This posed significant challenges for ingesting data and displaying it in a visually meaningful way.To address this, the LangChain team improved their ingestion to efficiently process and store large volumes of trace data. They also improved LangSmith’s frontend rendering to display long-running agent traces seamlessly.Search and filter within traces to pinpoint issuesLangSmith has always supported search between traces, which allows users to find a single trace among hundreds of thousands based on events or full text search. But as Replit Agent’s traces got longer and longer, the Replit team needed to search within traces for specific events (oftentimes issues reported by alpha testers). This required augmenting existing search capabilities.In response, a new search pattern – searching within traces – was added to LangSmith. Instead of sifting and scrolling call-by-call within a large trace, users could now filter directly on a criteria they cared about (e.g. keywords in the inputs or outputs of a run). This greatly reduced Replit’s time needed to debug agent steps within a trace.Thread view to enable human-in-the-loop workflowsA key differentiator of Replit Agent was its emphasis on human-in-the-loop workflows. Replit Agent intends to be a tool where AI agents can collaborate effectively with human developers, who can come in and edit and correct agent trajectories as needed.With separate agents to perform roles like managing, editing, and verifying generated code,\\xa0 Replit’s agents interacted with users continuously - often over long periods with multiple turns of conversation. However, monitoring these conversational flows was often difficult, as each user session would generate disjoint traces.\\xa0To solve this, LangSmith’s thread view helped collate traces from multiple threads together that were related (i.e. from one conversation). This provided a logical view of all agent-user interactions across a multi-turn conversation, helping Replit better 1) find bottlenecks where users got stuck and 2) pinpoint areas where human intervention could be beneficial.\\xa0ConclusionReplit is pushing the frontier of AI agent monitoring using LangSmith’s powerful observability features. By reducing the effort of loading long, heavy traces, the Replit team has greatly sped up the process of building and scaling complex agents. With faster debugging, improved trace visibility, and better handling of parallel tasks, Replit is setting the standard for AI-driven development.\\t\\n'),\n",
       " Document(metadata={'source': 'https://blog.langchain.dev/langgraph-v0-2/'}, page_content=\"\\nToday, we’re excited to announce the stable release of LangGraph v0.2, which introduces a new ecosystem of LangGraph checkpointer libraries. These simplify the creation and customization of checkpointers, which allows users to build more resilient LLM applications with smooth session memory, robust error recovery, and human-in-the-loop features.Why we built LangGraph v0.2One of the key pillars of LangGraph is its built-in persistence layer, implemented through checkpointers. When you use a checkpointer with a graph, you can interact with and manage the graph's state. The checkpointer saves a checkpoint of the graph state at each step, enabling several powerful capabilities, including:Session memory: Store history (checkpoints) of user interactions and resume from a saved checkpoint in follow up interactionsError recovery: Recover from failures at any given step in the graph execution by continuing from the last successful step checkpointHuman-in-the-loop: Implement tool approval, wait for human input, edit agent actions and moreTime travel: Edit graph state at any point in the history of execution and create an alternative execution from that point in time (i.e. fork the thread)Since the early days of LangGraph, we’ve designed checkpointing to be database-agnostic, allowing users to implement their own checkpointer adapters for their database of choice.Since the LangGraph v0.1 release, we've seen a lot of interest from the community in creating checkpointers for many popular databases like Postgres, Redis, and MongoDB. However, there was no clear blueprint for the users to implement their own, custom checkpointers.New checkpointer libraries in LangGraphWith LangGraph v0.2, we’re making it easier to create new checkpointers. We’ve also laid the foundation to foster a community-maintained ecosystem of checkpointer implementations.We now have a suite of new, dedicated checkpointer libraries:langgraph_checkpoint : The base interface for checkpointer savers (BaseCheckpointSaver ) and serialization/deserialization interface (SerializationProtocol). Includes in-memory checkpointer implementation (MemorySaver) for experimentation.langgraph_checkpoint_sqlite : An implementation of LangGraph checkpointer that uses SQLite database. Ideal for experimentation and local workflows.langgraph_checkpoint_postgres : Our advanced checkpointer that we wrote and optimized for Postgres in LangGraph Cloud is now open-sourced and available to the community to build upon. Ideal for using in production.Checkpointer implementations can be used interchangeably, which lets users tailor their stateful LangGraph applications to their custom needs.LangGraph Postgres Checkpointer for production-ready appslanggraph_checkpoint_postgres implementation can serve as a blueprint for community members to implement their own optimized, production-ready checkpointers for their favorite database. Postgres checkpointer implements a number of optimizations both on the write-, as well as read-side.Write-side optimizations:We're making use of Postgres pipeline mode to reduce database roundtripsWe're storing each channel value separately and versioned so that each new checkpoint only stores the values that changed.Read-side optimizations:We're making use of a cursor for the list endpoint in order to efficiently fetch long thread histories when needed.Getting started on LangGraph v0.2Since LangGraph checkpointer libraries are implemented as namespace packages, you can import checkpointer interfaces and implementations the same way as before, using:from langgraph.checkpoint.base import BaseCheckpointSaverfrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.checkpoint.sqlite import SqliteSaverfrom langgraph.checkpoint.postgres import PostgresSaverSince SQLite and Postgres checkpointers are provided via separate libraries, you will need to install them using pip install langgraph-checkpoint-sqlite or pip install langgraph-checkpoint-postgres.LangGraph checkpoint libraries will follow semantic versioning (starting with current release of 1.0), and any breaking changes in the main library will result in a major version bump for those libraries. For example, the next breaking change in langgraph_checkpoint will result in 2.0 version, and you can expect the checkpointer implementations (e.g.,langgraph_checkpoint_sqlite) to also be updated to 2.0 to follow that change.To get started, follow this guide on how to use checkpointers in LangGraph. You can also check out our documentation, including a reference and overview of checkpointers. Run agents at scale with LangGraph CloudTo complement the LangGraph framework, we also have a new runtime, LangGraph Cloud, which provides infrastructure purpose-built for deploying agents at scale.LangGraph Cloud does the heavy lifting for your agentic application, removing the maintenance work for custom checkpointers while adding fault-tolerant scalability. It gracefully manages horizontally-scaling task queues, servers, and includes our robust Postgres checkpointer out-of-the-box to help you handle many concurrent users and efficiently store large states and threads.In addition, LangGraph Cloud supports real-world interaction patterns beyond streaming and human-in-the-loop. These include double-texting to handle new user inputs on currently-running threads of the graph, async background jobs for long-running tasks, and cron jobs.Lastly, you can easily deploy your agentic app and collaborate in LangGraph Studio, a playground-like space for visualizing and debugging agent trajectories, with LangGraph Cloud. The LangGraph Studio desktop app is now also available for all LangSmith users to try for free.LangGraph Cloud is now available in beta for all LangSmith users on Plus or Enterprise plans. Try it out today for free by signing up for LangSmith.Additional changes in LangGraph v0.2LangGraph v0.2 contains many improvements, and we've designed it to be largely backwards compatible. Below is a list of breaking changes and deprecations in this latest version.Breaking changesLangGraph v0.2 introduces several breaking changes:thread_ts and parent_ts have been renamed to checkpoint_id and parent_checkpoint_id , respectively (via langgraph_checkpoint==1.0.0).Note: LangGraph checkpointers still recognize thread_ts if passed via config and treat it as checkpoint_idRe-exported imports like from langgraph.checkpoint import BaseCheckpointSaver are no longer possible due to the use of namespace packages. Instead, use from langgraph.checkpoint.base import BaseCheckpointSaverSQLite checkpointers have been moved to a separate library, so you’ll need to install them separately using pip install langgraph-checkpoint-sqliteDeprecationsIn LangGraph v0.2, we've removed:langgraph.prebuilt.chat_agent_executor.create_function_calling_executor . We recommend you use langgraph.prebuilt.chat_agent_executor.create_react_agent instead.langgraph.prebuilt.agent_executor . We recommend you use langgraph.prebuilt.chat_agent_executor.create_react_agent instead.ConclusionWe are incredibly grateful to our community and users for pushing us and building with LangGraph to improve agent reliability. We hope that with LangGraph v0.2, you’ll find it easier to build and maintain your own checkpointer implementations– and we’re excited to see all the apps that you create.As you try out LangGraph v0.2, we'd love to hear your feedback at hello@langchain.dev. You can also learn more from these additional resources:LangGraph docsLangGraph webpage (with FAQs)\\n\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 여러 개의 url 지정 가능\n",
    "url1 = \"https://blog.langchain.dev/customers-replit/\"\n",
    "url2 = \"https://blog.langchain.dev/langgraph-v0-2/\"\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(url1, url2), # 두 가지 경로를 설정\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"article-header\", \"article-content\") # 특정 갈래만 가져온다\n",
    "            # class_=(\"article-header\") # 특정 갈래만 가져온다\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "page_content='\n",
      "Replit is at the forefront of AI innovation with its platform that simplifies writing, running, and collaborating on code for over 30+ million developers. They recently released Replit Agent, which immediately went viral due to the incredible applications people could easily create with this tool.Behind the scenes, Replit Agent has a complex workflow built on LangGraph, which enables a highly custom agentic workflow with a high-degree of control and parallel execution. A major benefit of using LangGraph was the seamless integration with LangSmith, which gave Replit deep visibility into their agent interactions to debug tricky issues. The level of complexity required for Replit Agent also pushed the boundaries of LangSmith. The LangChain and Replit teams worked closely together to add functionality to LangSmith that would satisfy their LLM observability needs. Specifically, there were three main areas that we innovated on:Improved performance and scale on large tracesAbility to search and filter within tracesThread view to enable human-in-the loop workflowsImproved performance and scale on large tracesMost other LLMOps solutions monitor individual API requests to LLM providers, offering a limited view of single LLM calls. In contrast, LangSmith from day one has focused on tracing the entire execution flow of an LLM application to provide a more holistic context. Tracing is important for agents due to their complex nature. It captures multiple LLM calls as well as other steps (retrieval, running code, etc). This gives you granular visibility into what’s happening, including at the inputs and outputs of each step, in order to understand the agent’s decision-making. Replit Agent was a ripe example for advanced tracing needs. Their agentic tool goes beyond simply reviewing and writing code, but also performs a wider range of functions – including planning, creating dev environments, installing dependencies, and deploying applications for users. As a result, Replit’s traces were very large - involving hundreds of steps. This posed significant challenges for ingesting data and displaying it in a visually meaningful way.To address this, the LangChain team improved their ingestion to efficiently process and store large volumes of trace data. They also improved LangSmith’s frontend rendering to display long-running agent traces seamlessly.Search and filter within traces to pinpoint issuesLangSmith has always supported search between traces, which allows users to find a single trace among hundreds of thousands based on events or full text search. But as Replit Agent’s traces got longer and longer, the Replit team needed to search within traces for specific events (oftentimes issues reported by alpha testers). This required augmenting existing search capabilities.In response, a new search pattern – searching within traces – was added to LangSmith. Instead of sifting and scrolling call-by-call within a large trace, users could now filter directly on a criteria they cared about (e.g. keywords in the inputs or outputs of a run). This greatly reduced Replit’s time needed to debug agent steps within a trace.Thread view to enable human-in-the-loop workflowsA key differentiator of Replit Agent was its emphasis on human-in-the-loop workflows. Replit Agent intends to be a tool where AI agents can collaborate effectively with human developers, who can come in and edit and correct agent trajectories as needed.With separate agents to perform roles like managing, editing, and verifying generated code,  Replit’s agents interacted with users continuously - often over long periods with multiple turns of conversation. However, monitoring these conversational flows was often difficult, as each user session would generate disjoint traces. To solve this, LangSmith’s thread view helped collate traces from multiple threads together that were related (i.e. from one conversation). This provided a logical view of all agent-user interactions across a multi-turn conversation, helping Replit better 1) find bottlenecks where users got stuck and 2) pinpoint areas where human intervention could be beneficial. ConclusionReplit is pushing the frontier of AI agent monitoring using LangSmith’s powerful observability features. By reducing the effort of loading long, heavy traces, the Replit team has greatly sped up the process of building and scaling complex agents. With faster debugging, improved trace visibility, and better handling of parallel tasks, Replit is setting the standard for AI-driven development.\t\n",
      "' metadata={'source': 'https://blog.langchain.dev/customers-replit/'}\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('history.txt')\n",
    "data = loader.load()\n",
    "\n",
    "print(type(data))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'history.txt'}, page_content='한국의 역사는 수천 년에 걸쳐 이어져 온 긴 여정 속에서 다양한 문화와 전통이 형성되고 발전해 왔습니다. 고조선에서 시작해 삼국 시대의 경쟁, 그리고 통일 신라와 고려를 거쳐 조선까지, 한반도는 많은 변화를 겪었습니다.\\n\\n고조선은 기원전 2333년 단군왕검에 의해 세워졌다고 전해집니다. 이는 한국 역사상 최초의 국가로, 한민족의 시원이라 할 수 있습니다. 이후 기원전 1세기경에는 한반도와 만주 일대에서 여러 소국이 성장하며 삼한 시대로 접어듭니다.\\n\\n4세기경, 고구려, 백제, 신라의 삼국이 한반도의 주요 세력으로 부상했습니다. 이 시기는 삼국이 각각 문화와 기술, 무력을 발전시키며 경쟁적으로 성장한 시기로, 한국 역사에서 중요한 전환점을 마련했습니다. 특히 고구려는 북방의 강대국으로 성장하여 중국과도 여러 차례 전쟁을 벌였습니다.\\n\\n7세기 말, 신라는 당나라와 연합하여 백제와 고구려를 차례로 정복하고, 한반도 최초의 통일 국가인 통일 신라를 건립합니다. 이 시기에 신라는 불교를 국교로 채택하며 문화와 예술이 크게 발전했습니다.\\n\\n그러나 10세기에 이르러 신라는 내부의 분열과 외부의 압력으로 쇠퇴하고, 이를 대체하여 고려가 성립됩니다. 고려 시대에는 과거제도의 도입과 더불어 청자 등 고려 고유의 문화가 꽃피었습니다.\\n\\n조선은 1392년 이성계에 의해 건국되어, 1910년까지 이어졌습니다. 조선 초기에는 세종대왕이 한글을 창제하여 백성들의 문해율을 높이는 등 문화적, 과학적 성취가 이루어졌습니다. 그러나 조선 후기에는 내부적으로 실학의 발전과 함께 사회적 변화가 모색되었으나, 외부로부터의 압력은 점차 커져만 갔습니다.\\n\\n19세기 말부터 20세기 초에 걸쳐 한국은 제국주의 열강의 침략을 받으며 많은 시련을 겪었습니다. 1910년, 한국은 일본에 의해 강제로 병합되어 35년간의 식민 지배를 받게 됩니다. 이 기간 동안 한국인들은 독립을 위한 다양한 운동을 전개했으며, 이는 1945년 일본의 패망으로 이어지는 독립으로 결실을 맺었습니다.\\n\\n해방 후 한반도는 남북으로 분단되어 각각 다른 정부가 수립되었고, 1950년에는 한국전쟁이 발발하여 큰 피해를 입었습니다. 전쟁 후 남한은 빠른 경제 발전을 이루며 오늘날에 이르렀습니다.\\n\\n한국의 역사는 오랜 시간 동안 수많은 시련과 도전을 겪으며 형성된 깊은 유산을 지니고 있습니다. 오늘날 한국은 그 역사적 배경 위에서 세계적으로 중요한 역할을 하고 있으며, 과거의 역사가 현재와 미래에 어떻게 영향을 미치는지를 이해하는 것은 매우 중요합니다.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'history.txt'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 디렉토리 폴더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./history.txt', './places.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "files = glob(os.path.join('./', '*.txt'))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이와 같은 작업을 langchain_community.document_loaders의 DirectoryLoader 클래스를 사용하여 수행할 수 있습니다. DirectoryLoader는 지정된 경로와 glob 패턴에 맞는 파일을 찾아서 로드합니다.\n",
    "\n",
    "len(data)는 로드된 데이터의 길이, 즉 .txt 파일의 개수를 반환합니다. 이는 DirectoryLoader가 지정된 패턴에 맞는 모든 파일을 로드하고, 각 파일의 내용을 리스트의 각 항목으로 저장하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(path='./', glob='*.txt', loader_cls=TextLoader)\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'places.txt'}, page_content='경복궁\\n서울의 중심에 위치한 경복궁은 조선 시대의 왕궁으로, 한국의 역사와 전통 문화를 체험할 수 있는 대표적인 명소입니다. 광활한 궁궐 안에는 경회루, 근정전 등 다양한 전통 건축물이 있으며, 정기적으로 궁궐 경비 교대식과 전통 공연이 열립니다.\\n\\n남산 서울타워\\n서울의 스카이라인을 대표하는 남산 서울타워는 서울 시내를 한눈에 볼 수 있는 최고의 전망대입니다. 타워 주변의 남산 공원은 산책과 휴식을 즐기기에 적합하며, 연인들의 자물쇠 벽도 유명합니다.\\n\\n부산 해운대 해수욕장\\n부산의 해운대 해수욕장은 국내외 관광객에게 사랑받는 한국 최대의 해수욕장 중 하나입니다. 넓은 백사장과 도심 속의 접근성이 좋은 위치로, 여름철에는 수많은 피서객으로 붐빕니다.\\n\\n제주도\\n한국의 남쪽에 위치한 제주도는 화산섬으로, 아름다운 자연 풍경과 독특한 문화를 자랑합니다. 세계 자연 유산에 등재된 한라산, 청정 해변, 용두암 등 다양한 자연 명소와 함께 특색 있는 음식과 문화가 관광객을 맞이합니다.\\n\\n경주\\n신라 천년의 고도 경주는 한국의 역사적인 도시 중 하나로, 불국사, 석굴암, 첨성대 등 수많은 유적지와 문화재가 있습니다. 신라의 역사와 문화를 체험할 수 있는 최적의 장소입니다.\\n\\n인사동\\n서울의 인사동은 전통 찻집, 공예품 가게, 갤러리가 즐비한 문화 예술의 거리입니다. 한국의 전통 문화와 현대 예술이 공존하는 이곳에서는 다양한 기념품을 구입하고 전통 차를 맛볼 수 있습니다.\\n\\n한강\\n서울을 가로지르는 한강은 도시의 휴식처로, 한강공원, 자전거 도로, 피크닉 장소 등을 제공합니다. 야경이 아름다운 한강에서는 다양한 레저 활동과 행사가 열리며, 여름에는 불꽃놀이 축제가 인기입니다.\\n\\n순천만 국가정원\\n전라남도 순천에 위치한 순천만 국가정원은 다양한 식물과 아름다운 정원이 조화를 이루는 곳으로, 자연과 함께하는 힐링의 시간을 제공합니다. 인근의 순천만 습지는 천연 기념물로 지정된 생태 관광지입니다.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='한국주택금융공사_주택금융관련_지수_20160101.csv', encoding='cp949')\n",
    "data = loader.load()\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '한국주택금융공사_주택금융관련_지수_20160101.csv', 'row': 0}, page_content='연도: 2004-01-01\\n전국소득대비 주택가격 비율: 4.21\\n서울소득대비 주택가격 비율: 4.89\\n부산소득대비 주택가격 비율: 3.95\\n대구소득대비 주택가격 비율: 3.73\\n인천소득대비 주택가격 비율: 4.65\\n광주소득대비 주택가격 비율: 2.81\\n대전소득대비 주택가격 비율: 4.68\\n울산소득대비 주택가격 비율: 2.66\\n세종소득대비 주택가격 비율: 0\\n경기소득대비 주택가격 비율: 4.17\\n강원소득대비 주택가격 비율: 2.49\\n충북소득대비 주택가격 비율: 2.62\\n충남소득대비 주택가격 비율: 2.17\\n전북소득대비 주택가격 비율: 3.12\\n전남소득대비 주택가격 비율: 2.12\\n경북소득대비 주택가격 비율: 2.12\\n경남소득대비 주택가격 비율: 3.81\\n제주소득대비 주택가격 비율: 2.99\\n전국평균 대출금액  평균 연소득: 2.36\\n서울평균 대출금액  평균 연소득: 2.61\\n부산평균 대출금액  평균 연소득: 2.35\\n대구평균 대출금액  평균 연소득: 2.24\\n인천평균 대출금액  평균 연소득: 2.7\\n광주평균 대출금액  평균 연소득: 1.6\\n대전평균 대출금액  평균 연소득: 2.26\\n울산평균 대출금액  평균 연소득: 1.67\\n세종평균 대출금액  평균 연소득: 0\\n경기평균 대출금액  평균 연소득: 2.42\\n강원평균 대출금액  평균 연소득: 1.44\\n충북평균 대출금액  평균 연소득: 1.53\\n충남평균 대출금액  평균 연소득: 1.21\\n전북평균 대출금액  평균 연소득: 1.9\\n전남평균 대출금액  평균 연소득: 1.42\\n경북평균 대출금액  평균 연소득: 1.31\\n경남평균 대출금액  평균 연소득: 2.06\\n제주평균 대출금액  평균 연소득: 1.28')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
